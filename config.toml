[config]
    input_video_path = "input_videos"
    output_audio_path = "output_audios"
    output_text_path = "output_text"
    temp_path = "temp"

[pyannote]
    auth_key = ""

[whisper]
    model = "mlx-community/whisper-large-v3-turbo"

[openai_server]
    url = "http://localhost:1234/v1"
    api_key = "sk-1234"
    model = "llama-3.3-70b-instruct"
    
